"""Wrapper for Claude Code CLI interactions.

This module provides a Python interface to the Claude Code CLI tool,
handling subprocess execution, JSON parsing, session management,
and automatic retry with exponential backoff for transient failures.
"""

import json
import logging
import random
import subprocess
import time
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any

from .exceptions import ClaudeNotFoundError, ClaudeResponseError, ClaudeTimeoutError

logger = logging.getLogger(__name__)


@dataclass
class TokenUsage:
    """Token usage statistics from a Claude API call.

    Tracks input tokens, output tokens, and cache statistics for
    cost monitoring and efficiency optimization.

    Attributes:
        input_tokens: Number of tokens in the prompt/context.
        output_tokens: Number of tokens generated by Claude.
        cache_read_tokens: Tokens read from cache (reduced cost).
        cache_creation_tokens: Tokens written to cache.
    """
    input_tokens: int = 0
    output_tokens: int = 0
    cache_read_tokens: int = 0
    cache_creation_tokens: int = 0

    @property
    def total_tokens(self) -> int:
        """Total tokens used (input + output)."""
        return self.input_tokens + self.output_tokens

    def to_dict(self) -> dict[str, int]:
        """Convert to dictionary for serialization."""
        return {
            "input_tokens": self.input_tokens,
            "output_tokens": self.output_tokens,
            "cache_read_tokens": self.cache_read_tokens,
            "cache_creation_tokens": self.cache_creation_tokens,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "TokenUsage":
        """Create TokenUsage from a dictionary.

        Handles missing fields gracefully by defaulting to 0.
        """
        return cls(
            input_tokens=data.get("input_tokens", 0),
            output_tokens=data.get("output_tokens", 0),
            cache_read_tokens=data.get("cache_read_tokens", 0),
            cache_creation_tokens=data.get("cache_creation_tokens", 0),
        )

    def __add__(self, other: "TokenUsage") -> "TokenUsage":
        """Add two TokenUsage instances together."""
        if not isinstance(other, TokenUsage):
            return NotImplemented
        return TokenUsage(
            input_tokens=self.input_tokens + other.input_tokens,
            output_tokens=self.output_tokens + other.output_tokens,
            cache_read_tokens=self.cache_read_tokens + other.cache_read_tokens,
            cache_creation_tokens=self.cache_creation_tokens + other.cache_creation_tokens,
        )


def _parse_token_usage(raw_output: dict[str, Any] | None) -> TokenUsage:
    """Extract token usage from Claude CLI JSON output.

    The Claude CLI returns token usage in various formats depending on version.
    This function handles multiple possible structures gracefully.

    Args:
        raw_output: The raw JSON output from Claude CLI.

    Returns:
        TokenUsage with extracted values, or empty TokenUsage if not found.
    """
    if not raw_output:
        return TokenUsage()

    # Try common locations for usage data in Claude CLI output
    usage_data: dict[str, Any] = {}

    # Direct "usage" field
    if "usage" in raw_output and isinstance(raw_output["usage"], dict):
        usage_data = raw_output["usage"]
    # Nested in "metadata" or "stats"
    elif "metadata" in raw_output and isinstance(raw_output["metadata"], dict):
        usage_data = raw_output["metadata"].get("usage", {})
    elif "stats" in raw_output and isinstance(raw_output["stats"], dict):
        usage_data = raw_output["stats"]
    # Cost report field (some CLI versions)
    elif "cost_usd" in raw_output or "total_cost" in raw_output:
        # Extract from top-level if tokens are there
        usage_data = raw_output

    return TokenUsage(
        input_tokens=_safe_int(usage_data.get("input_tokens")),
        output_tokens=_safe_int(usage_data.get("output_tokens")),
        cache_read_tokens=_safe_int(
            usage_data.get("cache_read_tokens")
            or usage_data.get("cache_read_input_tokens")
        ),
        cache_creation_tokens=_safe_int(
            usage_data.get("cache_creation_tokens")
            or usage_data.get("cache_creation_input_tokens")
        ),
    )


def _safe_int(value: Any) -> int:
    """Safely convert a value to int, returning 0 on failure."""
    if value is None:
        return 0
    try:
        return int(value)
    except (ValueError, TypeError):
        return 0


# Retry configuration constants
DEFAULT_MAX_RETRIES = 3
DEFAULT_BASE_DELAY = 1.0  # seconds
DEFAULT_MAX_DELAY = 60.0  # seconds
DEFAULT_BACKOFF_MULTIPLIER = 2.0
DEFAULT_JITTER_FACTOR = 0.25  # +/- 25% jitter


def _calculate_backoff_delay(
    attempt: int,
    base_delay: float = DEFAULT_BASE_DELAY,
    max_delay: float = DEFAULT_MAX_DELAY,
    multiplier: float = DEFAULT_BACKOFF_MULTIPLIER,
    jitter_factor: float = DEFAULT_JITTER_FACTOR,
) -> float:
    """Calculate exponential backoff delay with jitter.

    Args:
        attempt: Current retry attempt (0-indexed).
        base_delay: Initial delay in seconds.
        max_delay: Maximum delay cap in seconds.
        multiplier: Exponential multiplier for each attempt.
        jitter_factor: Random jitter factor (0.25 = +/- 25%).

    Returns:
        Delay in seconds with jitter applied.
    """
    # Calculate exponential delay
    delay = base_delay * (multiplier ** attempt)

    # Cap at max_delay
    delay = min(delay, max_delay)

    # Apply jitter: random value in range [delay * (1 - jitter), delay * (1 + jitter)]
    jitter_range = delay * jitter_factor
    delay = delay + random.uniform(-jitter_range, jitter_range)

    # Ensure non-negative
    return max(0.0, delay)


def _is_retryable_error(error: str | None, returncode: int | None) -> bool:
    """Determine if an error is transient and worth retrying.

    Args:
        error: Error message string.
        returncode: Process return code.

    Returns:
        True if the error appears transient and retryable.
    """
    if error is None:
        return False

    error_lower = error.lower()

    # Network/connection errors (transient)
    transient_patterns = [
        "connection",
        "timeout",
        "network",
        "econnreset",
        "econnrefused",
        "etimedout",
        "rate limit",
        "too many requests",
        "429",
        "503",
        "502",
        "504",
        "overloaded",
        "temporarily unavailable",
        "service unavailable",
        "internal server error",
        "500",
    ]

    for pattern in transient_patterns:
        if pattern in error_lower:
            return True

    # Specific return codes that may be transient
    if returncode is not None and returncode in (1, 75, 124):
        # 75 = temp failure, 124 = timeout on some systems
        return True

    return False


@dataclass
class ClaudeResponse:
    """Structured response from Claude Code CLI.

    Attributes:
        success: Whether the call completed successfully.
        result: The text result from Claude.
        raw_output: The raw JSON output from the CLI (if available).
        error: Error message if the call failed.
        session_id: Session ID for resuming conversations.
        usage: Token usage statistics for this call.
        model_used: The model that was used for this call (if known).
    """
    success: bool
    result: str
    raw_output: dict[str, Any] | None = None
    error: str | None = None
    session_id: str | None = None
    usage: TokenUsage = field(default_factory=TokenUsage)
    model_used: str | None = None
    

class ClaudeCodeInterface:
    """
    Interface to Claude Code CLI for scripted/agentic use.
    
    Claude Code CAN and WILL edit files directly when given permission.
    This is the core mechanism for the self-improving loop.
    """
    
    def __init__(
        self,
        working_dir: Path,
        allowed_tools: list[str] | None = None,
        model: str | None = None,
        timeout: int = 600,
        max_retries: int = DEFAULT_MAX_RETRIES,
    ):
        self.working_dir = Path(working_dir).resolve()
        self.allowed_tools = allowed_tools or [
            "Bash(*)",      # Run any shell command
            "Read(*)",      # Read any file
            "Edit(*)",      # Edit any file (THIS IS THE KEY ONE)
            "Write(*)",     # Create new files
            "Glob(*)",      # Find files by pattern
            "Grep(*)",      # Search file contents
        ]
        self.model = model
        self.timeout = timeout
        self.max_retries = max_retries
        self.session_id: str | None = None

        self._verify_cli()
    
    def _verify_cli(self) -> None:
        """Verify Claude Code CLI is installed and accessible.

        Raises:
            ClaudeNotFoundError: If the Claude CLI is not installed or not in PATH.
            ClaudeResponseError: If the CLI returns an error on version check.
        """
        try:
            result = subprocess.run(
                ["claude", "--version"],
                capture_output=True,
                text=True,
                timeout=10
            )
            if result.returncode != 0:
                raise ClaudeResponseError(
                    reason="CLI version check failed",
                    raw_output=result.stderr
                )
            logger.info(f"Claude CLI version: {result.stdout.strip()}")
        except FileNotFoundError as err:
            raise ClaudeNotFoundError() from err
    
    def _build_command(
        self,
        prompt: str,
        max_turns: int | None = None,
        resume: bool = False,
        model_override: str | None = None,
    ) -> tuple[list[str], str | None]:
        """Build the claude CLI command.

        Args:
            prompt: The prompt to send.
            max_turns: Maximum agentic turns (unused, for future).
            resume: Whether to resume from previous session.
            model_override: Optional model to use instead of default.

        Returns:
            Tuple of (command list, model being used).
        """
        cmd = [
            "claude",
            "-p", prompt,                          # Non-interactive prompt mode
            "--output-format", "json",             # Machine-readable output
            "--dangerously-skip-permissions",      # Auto-accept all tool use
            "--allowedTools", ",".join(self.allowed_tools),
        ]

        # Determine which model to use
        effective_model = model_override or self.model
        if effective_model:
            cmd.extend(["--model", effective_model])

        # Resume previous session for context continuity
        if resume and self.session_id:
            cmd.extend(["--resume", self.session_id])

        # Note: max_turns not directly supported, handled by model
        _ = max_turns

        return cmd, effective_model
    
    def _execute_single_call(
        self,
        cmd: list[str],
        prompt_preview: str = "",
        model_used: str | None = None,
    ) -> ClaudeResponse:
        """Execute a single Claude CLI call without retry logic.

        Args:
            cmd: The command list to execute.
            prompt_preview: First 100 chars of prompt for error context.
            model_used: The model being used for this call.

        Returns:
            ClaudeResponse from this single execution attempt.
        """
        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout,
                cwd=self.working_dir,
            )

            # Parse JSON output - defensive handling for None/empty stdout
            stdout = result.stdout or ""
            stderr = result.stderr or ""

            if stdout.strip():
                try:
                    output = json.loads(stdout)

                    # Handle both dict and list responses defensively
                    # Claude CLI may return list format in some cases
                    if isinstance(output, list):
                        # Extract from list - try to find the main result
                        output_dict: dict[str, Any] = {}
                        result_text = ""
                        for item in output:
                            if isinstance(item, dict):
                                # Merge dict items, later items override
                                output_dict.update(item)
                                # Look for result text in various fields
                                if "result" in item:
                                    result_text = str(item["result"])
                                elif "message" in item:
                                    result_text = str(item["message"])
                                elif "text" in item:
                                    result_text = str(item["text"])
                            elif isinstance(item, str) and not result_text:
                                result_text = item

                        # Use extracted dict for metadata
                        output = output_dict
                        if not output.get("result") and result_text:
                            output["result"] = result_text

                    # Ensure output is a dict for safe .get() calls
                    if not isinstance(output, dict):
                        output = {"result": str(output)}

                    # Extract session ID for potential resume
                    self.session_id = output.get("session_id")

                    # Parse token usage from the output
                    usage = _parse_token_usage(output)
                    if usage.total_tokens > 0:
                        logger.debug(
                            f"Token usage: {usage.input_tokens} in, "
                            f"{usage.output_tokens} out, "
                            f"{usage.cache_read_tokens} cache read"
                        )

                    return ClaudeResponse(
                        success=result.returncode == 0,
                        result=str(output.get("result") or output.get("message") or str(output)),
                        raw_output=output,
                        session_id=self.session_id,
                        usage=usage,
                        model_used=model_used,
                    )
                except json.JSONDecodeError as e:
                    # Non-JSON output (shouldn't happen with --output-format json)
                    logger.warning(f"Failed to parse Claude output as JSON: {e}")
                    return ClaudeResponse(
                        success=result.returncode == 0,
                        result=stdout,
                        error=f"JSON parse error: {e}" if result.returncode != 0 else None,
                        model_used=model_used,
                    )
                except (TypeError, AttributeError) as e:
                    # Handle unexpected data structure issues
                    logger.warning(f"Unexpected data structure in Claude output: {e}")
                    return ClaudeResponse(
                        success=result.returncode == 0,
                        result=stdout,
                        error=f"Data structure error: {e}" if result.returncode != 0 else None,
                        model_used=model_used,
                    )
            else:
                error_msg = stderr.strip() if stderr.strip() else "No output from Claude CLI"
                return ClaudeResponse(
                    success=False,
                    result="",
                    error=error_msg,
                    model_used=model_used,
                )

        except subprocess.TimeoutExpired:
            # Create a structured timeout error for logging context
            timeout_error = ClaudeTimeoutError(self.timeout, prompt_preview)
            logger.error(str(timeout_error))
            return ClaudeResponse(
                success=False,
                result="",
                error=f"Timeout after {self.timeout}s",
                model_used=model_used,
            )
        except OSError as e:
            # Handle OS-level errors (permissions, resources, etc.)
            logger.error(f"OS error executing Claude CLI: {e}")
            return ClaudeResponse(
                success=False,
                result="",
                error=f"OS error: {e}",
                model_used=model_used,
            )
        except Exception as e:
            # Catch-all for unexpected errors
            logger.exception(f"Unexpected error executing Claude CLI: {e}")
            return ClaudeResponse(
                success=False,
                result="",
                error=f"Unexpected error: {e}",
                model_used=model_used,
            )

    def call(
        self,
        prompt: str,
        context: str | None = None,
        max_turns: int | None = None,
        resume: bool = False,
        model_override: str | None = None,
    ) -> ClaudeResponse:
        """Make a call to Claude Code CLI with automatic retry for transient errors.

        Claude WILL edit files in working_dir when instructed.
        Uses exponential backoff with jitter for retries on transient failures.

        Args:
            prompt: The instruction/prompt to send.
            context: Optional context to prepend.
            max_turns: Limit agentic turns (None = unlimited).
            resume: Continue from previous session.
            model_override: Optional model to use instead of default.

        Returns:
            ClaudeResponse with results.
        """
        full_prompt = f"{context}\n\n{prompt}" if context else prompt
        cmd, model_used = self._build_command(full_prompt, max_turns, resume, model_override)

        # Create prompt preview for error context (used in timeout errors)
        prompt_preview = prompt[:100]

        logger.debug(f"Executing: {' '.join(cmd)}")
        if model_used:
            logger.debug(f"Using model: {model_used}")
        logger.info(f"Prompt: {prompt_preview}...")

        last_response: ClaudeResponse | None = None

        for attempt in range(self.max_retries + 1):
            response = self._execute_single_call(cmd, prompt_preview, model_used)

            # Success - return immediately
            if response.success:
                if attempt > 0:
                    logger.info(f"Call succeeded on retry attempt {attempt}")
                return response

            # Check if this is a retryable error
            if not _is_retryable_error(response.error, None):
                # Non-retryable error - return immediately
                logger.debug(f"Non-retryable error: {response.error}")
                return response

            last_response = response

            # Check if we have retries remaining
            if attempt < self.max_retries:
                delay = _calculate_backoff_delay(attempt)
                logger.warning(
                    f"Transient error on attempt {attempt + 1}/{self.max_retries + 1}: "
                    f"{response.error}. Retrying in {delay:.1f}s..."
                )
                time.sleep(delay)
            else:
                logger.error(
                    f"All {self.max_retries + 1} attempts failed. "
                    f"Last error: {response.error}"
                )

        # Return the last failed response
        return last_response or ClaudeResponse(
            success=False,
            result="",
            error="All retry attempts exhausted",
            model_used=model_used,
        )
    
    def analyze(
        self,
        question: str,
        model_override: str | None = None,
    ) -> ClaudeResponse:
        """Ask Claude to analyze the repo without making changes.

        Args:
            question: The analysis question or prompt.
            model_override: Optional model to use instead of default.

        Returns:
            ClaudeResponse with analysis results.
        """
        return self.call(
            f"ANALYSIS ONLY - Do not edit any files.\n\n{question}",
            max_turns=5,
            model_override=model_override,
        )

    def improve(
        self,
        instruction: str,
        max_turns: int = 10,
        model_override: str | None = None,
    ) -> ClaudeResponse:
        """Ask Claude to make improvements to the repo.

        This WILL edit files.

        Args:
            instruction: The improvement instruction.
            max_turns: Maximum agentic turns.
            model_override: Optional model to use instead of default.

        Returns:
            ClaudeResponse with improvement results.
        """
        return self.call(
            f"Make the following improvements to this codebase:\n\n{instruction}",
            max_turns=max_turns,
            model_override=model_override,
        )
